---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
Hi there! My name is Hang Wu (Âê¥Êù≠), you can also call me by my English name Laurent.

I am currently a first-year PhD student at the University of California, Merced, conducting research under the guidance of Prof. [Yiwei Wang](https://wangywust.github.io/), with Prof. [Ming-Hsuan Yang](https://faculty.ucmerced.edu/mhyang/) as my senior advisor. Additionally, I work closely with Prof. [Yujun Cai](https://vanoracai.github.io/). My main research interests are in vision-language models and large multimodal models, with a focus on improving their performance and specific applications. I received my bachelor's degree from Tongji University, where I worked on image processing tasks in the low-level vision field.

You can find my CV here: [Hang Wu's Curriculum Vitae](https://drive.google.com/file/d/1tNOCYlOXXq9uFjwZmn2hUCbU-wdg_udY/view?usp=sharing). If you are interested in my work, please feel free to drop me an email.


# üî• News
- *2025.08*: üéâüéâ Our paper DiMo-GUI is accepted to EMNLP 2025 Main Conference! See you in Suzhou!
- *2025.05*: Two papers submitted to EMNLP 2025.
- *2025.04*: Thrilled to accept Ph.D offer from UC Merced. Looking forward to working and living in CA!
- *2025.03*: Join vivo as a Research Intern!
- *2024.11*: One paper submitted to CVPR 2025.
<!-- - *2024.11*: &nbsp;üéâüéâ One paper submitted to CVPR 2025! -->

# üìù Publications 

<div class='paper-box'>
  <div class='paper-box-image' style="text-align: center;">
    <div>
      <!-- <div class="badge">Arxiv 2025</div> -->
      <img src='images/DiMo-GUI.jpg' alt="sym" width="60%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

[DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning](https://wuhang03.github.io/DiMo-GUI-homepage/)

**Hang Wu**, Hongkai Chen$^{\dagger}$, Yujun Cai, Chang Liu, Qingwen Ye, Ming-Hsuan Yang, Yiwei Wang

<strong>EMNLP 2025 Main Conference</strong>
- We propose DiMo-GUI, a training-free framework that can be seamlessly integrated as a plug-and-play component into any GUI agent.
- Without requiring additional training or external data, DiMo-GUI effectively enhances grounding performance across various GUI tasks.
</div>
</div>

<div class='paper-box'>
  <div class='paper-box-image' style="text-align: center;">
    <div>
      <!-- <div class="badge">Arxiv 2025</div> -->
      <img src='images/structure.png' alt="sym" width="60%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

[Structured Attention Matters to Multimodal LLMs in Document Understanding](https://www.techrxiv.org/doi/full/10.36227/techrxiv.175086178.86227111/v1)

Chang LiuÔºåHongkai Chen$^{\dagger}$, Yujun Cai, **Hang Wu**, Qingwen Ye, Ming-Hsuan Yang, Yiwei Wang

<strong>Arxiv 2025</strong>
- Our work investigates a fundamental yet overlooked aspect: how input format influences document comprehension performance.
- We propose a novel structurepreserving approach that encodes document elements using the LATEX paradigm, maintaining the hierarchical organization and spatial relationships critical for comprehension.
</div>
</div>


<!-- 
# üéñ Honors and Awards
- *2022.09* Scholarship for Outstanding Students, Tongji University. -->

# üìñ Educations
- *2025.08 - Present*,  PhD student, University of California, Merced.
- *2021.09 - 2025.06*,  Undergraduate student, Tongji University.

<!-- 
# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->


# üìö Projects 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='../images/project1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Research on Perception-oriented High Dynamic Range Imaging Systems]()

[**Project**]() | <strong>National-level Innovation Project</strong>
-  We treat artifacts in HDR images as detectable entities, explicitly detect and suppress them to enhance HDR quality.
-  National-level innovation project at Tongji University, with a funding of 10,000 RMB.
</div>
</div>

# üíª Internships
- *2025.03 - 2025.07*, Research Intern, vivo@Shenzhen, China.
- *2025.01 - 2025.07*, Research Intern, UC Merced NLP Lab@University of California-Merced, Remote.
- *2023.09 - 2025.03*, Research Intern, Ni's Group@Tongji University, Shanghai, China.

# üí¨ Services
<strong>Conference Reviewers</strong>
- The IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026